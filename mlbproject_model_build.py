# -*- coding: utf-8 -*-
"""MLBProject_Model_Build.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tw_kO2ELxnwMlZMkkbhJknB9u4SP9dRG
"""

import pandas as pd
import numpy as np

"""# Import Data"""

data = pd.read_csv('/content/MLB_Train.csv', sep = ",")
#data
data.isna().sum()
data = data.dropna()




"""# Use columns of interest"""

data = data.drop(['date', 'away_team_errors', 'away_team_hits','away_team_runs',
                  'home_team_errors', 'home_team_hits', 
                  'home_team_runs', 'start_time', 'day_of_week', 'total_runs', 
                  'game_hours_dec', 'season', 'home_team_loss', 'home_team_outcome'], axis=1)
#data




"""# Change categorical variables, drop original"""

#away team
data.away_team = pd.Categorical(data.away_team)
data['away_team'] = data.away_team.cat.codes

#field_type
data.field_type = pd.Categorical(data.field_type)
data['field_type'] = data.field_type.cat.codes

#game_type
data.game_type = pd.Categorical(data.game_type)
data['game_type'] = data.game_type.cat.codes

#home_team
data.home_team = pd.Categorical(data.home_team)
data['home_team'] = data.home_team.cat.codes

#venue
data.venue = pd.Categorical(data.venue)
data['venue'] = data.venue.cat.codes

#wind_direction
data.wind_direction = pd.Categorical(data.wind_direction)
data['wind_direction'] = data.wind_direction.cat.codes

#sky
data.sky = pd.Categorical(data.sky)
data['sky'] = data.sky.cat.codes

#data
#data.info()




"""# Scale continuous variabes"""

from sklearn.preprocessing import MinMaxScaler
#data.info()
scaler = MinMaxScaler()
data[["attendance", "temperature", "wind_speed",
          "home_runs_for", "away_runs_for", 
          "home_runs_against", "away_runs_against", 
          "home_hits_for", "away_hits_for", "home_hits_against",
          "away_hits_against", "ballpark_factor", "home_run_diff", 
          "away_run_diff"]
     ] = scaler.fit_transform(data[["attendance", "temperature", "wind_speed",
          "home_runs_for", "away_runs_for", 
          "home_runs_against", "away_runs_against", 
          "home_hits_for", "away_hits_for", "home_hits_against",
          "away_hits_against", "ballpark_factor", "home_run_diff", 
          "away_run_diff"]
          ])

#data





"""# Randomize Data"""

from sklearn.utils import shuffle
data = shuffle(data, random_state=123)
data




"""# Train / Valid / Test Split (80/20 Split)"""

from sklearn.model_selection import train_test_split
train, test, = train_test_split(data, test_size = .20, random_state=379)
#train
#test

x_train = train.loc[:, train.columns != "home_team_win"]
y_train = train.loc[:, train.columns == "home_team_win"]
x_test = test.loc[:, test.columns != "home_team_win"]
y_test = test.loc[:, test.columns == "home_team_win"]





"""# Dummy Classifier (Baseline)"""

from sklearn.dummy import DummyClassifier
dummyx = data.loc[:, data.columns != "home_team_win"]
dummyy = data.loc[:, data.columns == "home_team_win"]
for strategy in ['stratified','most_frequent','prior',
               'uniform']:
    model_dummy = DummyClassifier(strategy = strategy)
    model_dummy.fit(dummyx,dummyy)
    print("The %s's accuracy is %f"%(strategy,model_dummy.score(dummyx,dummyy)))






"""# SVM Default"""

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.svm import SVC
model = SVC()
model.fit(x_train, y_train)
predictions = model.predict(x_test)
print(classification_report(y_test, predictions))





"""# SVM GridSearch"""

from sklearn.model_selection import GridSearchCV
parameters = {'C': [0.1, 1, 10, 100], 
              'gamma': [1, 0.1, 0.01, 0.001],
              'kernel': ['rbf']}   
SVCgrid = GridSearchCV(SVC(), parameters, refit = True, verbose = 3, cv = 10)
SVCgrid.fit(x_train, y_train)

print(SVCgrid.best_params_)
print(SVCgrid.best_estimator_)

best_SVC = SVC(C = 1, gamma = 0.01, kernel = 'rbf').fit(x_train, y_train)
best_pred = best_SVC.predict(x_test)
print(classification_report(y_test, best_pred))

'''did grid search on 90 / 10% train test split by accident, got 63% with parameters below, 
    used the paramters on this proper 80 / 20% split and got a better score'''
best_SVC2 = SVC(C = 100, gamma = 0.001, kernel = 'rbf').fit(x_train, y_train)
best_pred2 = best_SVC2.predict(x_test)
print(classification_report(y_test, best_pred2))






"""# Logistic Default"""

from sklearn.linear_model import LogisticRegression
Log = LogisticRegression().fit(x_train, y_train)
Log_pred = Log.predict(x_test) 
print(classification_report(y_test, Log_pred))





"""# Logistic GridSearch"""

'grid search for saga solver'
from sklearn import metrics
folds = np.array_split(train, 10)
penalty = ['l1', 'l2']
C = [0.001, 0.01, 0.1, 1, 10, 100]

acc_grid = []
#for every penalty
for p in range(len(penalty)):
  #for every learning rate
  for c in range(len(C)):
    #create new logistic regression model with each unique combination of hyperparameters
    logreg_grid = LogisticRegression(penalty = penalty[p], C = C[c], solver = 'saga')
    acc_grid.append("ACC with penalty:" + penalty[p] + " and C: " + str(C[c]))
    perf = []
    for i in range(0, 10):
      trainfolds = pd.concat(folds[:i] + folds[i+1:])
      traings_x = trainfolds.loc[:, trainfolds.columns != "home_team_win"]
      traings_y = trainfolds.loc[:, trainfolds.columns == "home_team_win"]
      
      model_grid = logreg_grid.fit(traings_x, traings_y)
      holdout_set = pd.DataFrame(folds[i])
      validgs_x = pd.DataFrame(holdout_set.loc[:, holdout_set.columns != "home_team_win"])
      validgs_y = pd.DataFrame(holdout_set.loc[:, holdout_set.columns == "home_team_win"])
      
      yhat = model_grid.predict(validgs_x)
      accuracy = metrics.accuracy_score(validgs_y, yhat)
      accuracy_percentage = 100 * accuracy
        #print(accuracy_percentage)
      perf.append(accuracy_percentage)
    best = max(perf)
    acc_grid.append(best)
  
acc_grid

'saga solver predictions score'
from sklearn.linear_model import LogisticRegression
best_log = LogisticRegression(C = 0.001, penalty = "l1", solver = 'saga').fit(x_train, y_train)
best_log_pred = best_log.predict(x_test) 
print(classification_report(y_test, best_log_pred))




'Logistic Grid Search for "liblinear" solver'
folds = np.array_split(train, 10)
penalty = ['l1', 'l2']
C = [0.001, 0.01, 0.1, 1, 10, 100]

acc_grid = []
#for every penalty
for p in range(len(penalty)):
  #for every learning rate
  for c in range(len(C)):
    #create new logistic regression model with each unique combination of hyperparameters
    logreg_grid = LogisticRegression(penalty = penalty[p], C = C[c], solver = 'liblinear')
    acc_grid.append("ACC with penalty:" + penalty[p] + " and C: " + str(C[c]))
    perf = []
    for i in range(0, 10):
      trainfolds = pd.concat(folds[:i] + folds[i+1:])
      traings_x = trainfolds.loc[:, trainfolds.columns != "home_team_win"]
      traings_y = trainfolds.loc[:, trainfolds.columns == "home_team_win"]
      
      model_grid = logreg_grid.fit(traings_x, traings_y)
      holdout_set = pd.DataFrame(folds[i])
      validgs_x = pd.DataFrame(holdout_set.loc[:, holdout_set.columns != "home_team_win"])
      validgs_y = pd.DataFrame(holdout_set.loc[:, holdout_set.columns == "home_team_win"])
      
      yhat = model_grid.predict(validgs_x)
      accuracy = metrics.accuracy_score(validgs_y, yhat)
      accuracy_percentage = 100 * accuracy
        #print(accuracy_percentage)
      perf.append(accuracy_percentage)
    best = max(perf)
    acc_grid.append(best)
  
acc_grid

'liblineal solver predictions score'
from sklearn.linear_model import LogisticRegression
best_log = LogisticRegression(C = 1, penalty = "l2", solver = 'liblinear').fit(x_train, y_train)
best_log_pred = best_log.predict(x_test) 
print(classification_report(y_test, best_log_pred))